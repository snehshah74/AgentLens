# AI Observability Backend Environment Variables

# LLM Provider Configuration
# Choose one of the following providers:

# Option 1: OpenAI (recommended for best results)
OPENAI_API_KEY=your_openai_api_key_here
LLM_PROVIDER=openai
LLM_MODEL=gpt-3.5-turbo

# Option 2: HuggingFace (free tier available)
# HUGGINGFACE_API_KEY=your_huggingface_api_key_here
# LLM_PROVIDER=huggingface
# LLM_MODEL=microsoft/DialoGPT-medium

# Option 3: Ollama (local, completely free)
# LLM_PROVIDER=ollama
# LLM_MODEL=llama2
# OLLAMA_BASE_URL=http://localhost:11434

# Option 4: Groq (fast and free tier)
# GROQ_API_KEY=your_groq_api_key_here
# LLM_PROVIDER=groq
# LLM_MODEL=llama2-70b-4096

# Security Analysis Configuration
SECURITY_ANALYSIS_ENABLED=true
LLM_ANALYSIS_ENABLED=true
CONFIDENCE_THRESHOLD=0.7

# Alert Configuration
ALERT_COOLDOWN_MINUTES=5
MAX_ALERTS_PER_HOUR=100

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# Database Configuration (for future use)
# DATABASE_URL=sqlite:///observability.db
# REDIS_URL=redis://localhost:6379

